#!/usr/bin/env python3
"""
Convert other source Excel format to Haidilao format.
This script transforms transactional POS data into the standard Haidilao format
with daily reports (è¥ä¸šåŸºç¡€è¡¨) and time segment reports (åˆ†æ—¶æ®µåŸºç¡€è¡¨).
"""

import pandas as pd
import numpy as np
import os
from pathlib import Path
import argparse
import sys
from datetime import datetime, timedelta
from openpyxl import Workbook
from openpyxl.styles import Font, Alignment, PatternFill, Border, Side

# Add the project root to sys.path to import local modules
sys.path.append(str(Path(__file__).parent.parent))
from utils.database import get_database_manager

def convert_currency_to_float(value):
    """Convert currency string to float."""
    if pd.isna(value) or value == "":
        return 0.0
    if isinstance(value, str):
        # Remove $ and convert to float
        return float(value.replace('$', '').replace(',', ''))
    return float(value)

def categorize_time_segment(timestamp_str):
    """Categorize timestamp into Haidilao time segments."""
    try:
        # Parse the timestamp
        dt = pd.to_datetime(timestamp_str)
        hour = dt.hour
        
        # Haidilao time segments
        if 8 <= hour < 14:
            return "08:00-13:59"
        elif 14 <= hour < 17:
            return "14:00-16:59"
        elif 17 <= hour < 22:
            return "17:00-21:59"
        else:  # 22:00 - 07:59 (next day)
            return "22:00-(æ¬¡)07:59"
    except:
        return "08:00-13:59"  # Default fallback

def get_store_info_from_database(store_name, store_code=None, is_test=False):
    """Get store information from database, including correct seat count."""
    try:
        db_manager = get_database_manager(is_test=is_test)
        
        # Test connection first
        if not db_manager.test_connection():
            print("âš ï¸  Database connection failed, using default values")
            return None
        
        # Query store information by name or code
        if store_code:
            result = db_manager.fetch_one(
                "SELECT * FROM store WHERE name = %s OR id = %s",
                (store_name, store_code)
            )
        else:
            result = db_manager.fetch_one(
                "SELECT * FROM store WHERE name = %s",
                (store_name,)
            )
        
        if result:
            return {
                'country': result['country'],
                'regional_manager': result['manager'],
                'store_name': result['name'],
                'store_code': str(result['id']),  # Use database ID as store code
                'opening_date': result['opened_at'].strftime('%Y-%m-%d') if result['opened_at'] else '2024-01-09',
                'holiday_type': 'èŠ‚å‡æ—¥',
                'total_seats': result['seats_total'],  # Get actual seat count from database
            }
        else:
            print(f"âš ï¸  Store '{store_name}' not found in database, using default values")
            return None
            
    except Exception as e:
        print(f"âš ï¸  Database query failed: {e}, using default values")
        return None

def process_daily_sheet(sheet_name, df, store_info):
    """Process a single day's transaction data and aggregate it."""
    # Skip empty or header-only sheets
    if df.shape[0] <= 2:
        return None
    
    # Find the header row (contains "æ—¶é—´", "è®¢å•ç¼–å·", etc.)
    header_row = None
    for i in range(min(5, df.shape[0])):
        if df.iloc[i, 0] and "æ—¶é—´" in str(df.iloc[i, 0]):
            header_row = i
            break
    
    if header_row is None:
        print(f"âš ï¸  Warning: Could not find header row in sheet {sheet_name}")
        return None
    
    # Set proper column names based on the actual structure
    columns = ['æ—¶é—´', 'è®¢å•ç¼–å·', 'æ¡Œå·', 'å°±é¤äººæ•°', 'è®¢å•ç¨å‰å®æ”¶é‡‘é¢Totals', 'è®¢å•ç¨é‡‘Tax', 'GST', 'QST', 
               'æŠ˜æ‰£é‡‘é¢ï¼ˆåˆè®¡ï¼‰', 'èµ èœé‡‘é¢ï¼ˆåˆè®¡ï¼‰', 'å…å•é‡‘é¢ï¼ˆåˆè®¡ï¼‰', 'è®¢å•ç±»å‹', 'è®¢å•ç¨å‰åº”æ”¶é‡‘é¢ï¼ˆä¸å«ç¨ï¼‰', 'å°è´¹', 'èˆå…¥', 'æ¡Œæ•°', 'é€€æ¬¾è®¢å•', 'è®¢å•æŠ˜æ‰£ç‡']
    data_df = df.iloc[header_row+1:].copy()
    
    # Handle case where there might be fewer columns than expected
    if data_df.shape[1] < len(columns):
        # Use the actual number of columns available
        actual_columns = columns[:data_df.shape[1]]
        data_df.columns = actual_columns
    else:
        data_df.columns = columns + [f'col_{i}' for i in range(len(columns), data_df.shape[1])]
    
    # Clean and convert data
    data_df = data_df.dropna(subset=['æ—¶é—´'])  # Remove rows without timestamp
    data_df['è®¢å•ç¨å‰å®æ”¶é‡‘é¢_float'] = data_df['è®¢å•ç¨å‰å®æ”¶é‡‘é¢Totals'].apply(convert_currency_to_float)
    data_df['å°±é¤äººæ•°'] = pd.to_numeric(data_df['å°±é¤äººæ•°'], errors='coerce').fillna(0)
    
    # Process additional columns if available
    if 'æ¡Œæ•°' in data_df.columns:
        data_df['æ¡Œæ•°'] = pd.to_numeric(data_df['æ¡Œæ•°'], errors='coerce').fillna(0)
    else:
        data_df['æ¡Œæ•°'] = 1  # Default to 1 table per order
    
    if 'è®¢å•æŠ˜æ‰£ç‡' in data_df.columns:
        data_df['è®¢å•æŠ˜æ‰£ç‡'] = pd.to_numeric(data_df['è®¢å•æŠ˜æ‰£ç‡'], errors='coerce').fillna(1.0)
    else:
        data_df['è®¢å•æŠ˜æ‰£ç‡'] = 1.0  # Default to 100% discount rate
    
    if 'é€€æ¬¾è®¢å•' in data_df.columns:
        data_df['æ˜¯å¦é€€æ¬¾'] = data_df['é€€æ¬¾è®¢å•'] == 'æ˜¯'
    else:
        data_df['æ˜¯å¦é€€æ¬¾'] = False
    
    if 'æŠ˜æ‰£é‡‘é¢ï¼ˆåˆè®¡ï¼‰' in data_df.columns:
        data_df['æŠ˜æ‰£é‡‘é¢_float'] = data_df['æŠ˜æ‰£é‡‘é¢ï¼ˆåˆè®¡ï¼‰'].apply(convert_currency_to_float).abs()  # Take absolute value
    else:
        data_df['æŠ˜æ‰£é‡‘é¢_float'] = 0.0
    
    # Parse date from sheet name
    date_str = sheet_name.replace('-', '')  # Convert 2025-06-22 to 20250622
    
    # Filter out refund orders (é€€æ¬¾è®¢å• = æ˜¯ or æ¡Œæ•° = 0)
    valid_orders = data_df[~data_df['æ˜¯å¦é€€æ¬¾'] & (data_df['æ¡Œæ•°'] > 0)]
    
    # Calculate è¥ä¸šæ¡Œæ•° = sum of all table counts (excluding refunds)
    è¥ä¸šæ¡Œæ•° = valid_orders['æ¡Œæ•°'].sum()
    
    # Calculate è¥ä¸šæ¡Œæ•°(è€ƒæ ¸) = sum(æ¡Œæ•° * è®¢å•æŠ˜æ‰£ç‡) where è®¢å•æŠ˜æ‰£ç‡ >= 0.7
    qualified_orders = valid_orders[valid_orders['è®¢å•æŠ˜æ‰£ç‡'] >= 0.7]
    è¥ä¸šæ¡Œæ•°_è€ƒæ ¸ = (qualified_orders['æ¡Œæ•°'] * qualified_orders['è®¢å•æŠ˜æ‰£ç‡']).sum()
    
    # Calculate revenue excluding refunds
    total_revenue = valid_orders['è®¢å•ç¨å‰å®æ”¶é‡‘é¢_float'].sum()
    total_customers = valid_orders['å°±é¤äººæ•°'].sum()
    
    # Calculate discount amount directly from the æŠ˜æ‰£é‡‘é¢ï¼ˆåˆè®¡ï¼‰ column
    total_discount = valid_orders['æŠ˜æ‰£é‡‘é¢_float'].sum()
    
    # Aggregate daily data with all required columns
    daily_data = {
        'æ—¥æœŸ': date_str,
        'å›½å®¶': store_info['country'],
        'å¤§åŒºç»ç†': store_info['regional_manager'],
        'é—¨åº—åç§°': store_info['store_name'],
        'é—¨åº—ç¼–ç ': store_info['store_code'],
        'å¼€ä¸šæ—¶é—´': store_info['opening_date'],
        'èŠ‚å‡æ—¥': store_info['holiday_type'],
        'æ‰€æœ‰é¤ä½æ•°': store_info['total_seats'],
        
        # Required columns for extraction system
        'è¥ä¸šæ¡Œæ•°': int(è¥ä¸šæ¡Œæ•°),  # Sum of all table counts (excluding refunds)
        'è¥ä¸šæ¡Œæ•°(è€ƒæ ¸)': round(è¥ä¸šæ¡Œæ•°_è€ƒæ ¸, 2),  # Sum of (table count * discount rate) where rate >= 0.7
        'ç¿»å°ç‡(è€ƒæ ¸)': round(è¥ä¸šæ¡Œæ•°_è€ƒæ ¸ / max(1, store_info['total_seats']), 2),  # Assessment turnover rate
        'è¥ä¸šæ”¶å…¥(ä¸å«ç¨)': round(total_revenue, 2),
        'è¥ä¸šæ¡Œæ•°(è€ƒæ ¸)(å¤–å–)': 0,  # Takeout table count (not applicable for this data)
        'å°±é¤äººæ•°': int(total_customers),
        'ä¼˜æƒ æ€»é‡‘é¢(ä¸å«ç¨)': round(total_discount, 2),  # Total discount amount
        
        # Additional business metrics
        'è¥ä¸šç¬”æ•°': len(valid_orders),
        'è¥ä¸šé¢': round(total_revenue, 2),
        'å¹³å‡å®¢å•ä»·': round(total_revenue / max(1, total_customers), 2) if total_customers > 0 else 0,
        'ç¿»å°ç‡': round(è¥ä¸šæ¡Œæ•° / max(1, store_info['total_seats']), 2),
        'è¥ä¸šæ—¶é•¿': 14,
        'å®¢æ»¡ç‡': round((è¥ä¸šæ¡Œæ•° / max(1, store_info['total_seats'])) * 100, 1),
    }
    
    return daily_data

def process_time_segment_sheet(sheet_name, df, store_info):
    """Process a single day's transaction data and break it down by time segments."""
    # Skip empty or header-only sheets
    if df.shape[0] <= 2:
        return []
    
    # Find the header row
    header_row = None
    for i in range(min(5, df.shape[0])):
        if df.iloc[i, 0] and "æ—¶é—´" in str(df.iloc[i, 0]):
            header_row = i
            break
    
    if header_row is None:
        return []
    
    # Set proper column names based on the actual structure
    columns = ['æ—¶é—´', 'è®¢å•ç¼–å·', 'æ¡Œå·', 'å°±é¤äººæ•°', 'è®¢å•ç¨å‰å®æ”¶é‡‘é¢Totals', 'è®¢å•ç¨é‡‘Tax', 'GST', 'QST', 
               'æŠ˜æ‰£é‡‘é¢ï¼ˆåˆè®¡ï¼‰', 'èµ èœé‡‘é¢ï¼ˆåˆè®¡ï¼‰', 'å…å•é‡‘é¢ï¼ˆåˆè®¡ï¼‰', 'è®¢å•ç±»å‹', 'è®¢å•ç¨å‰åº”æ”¶é‡‘é¢ï¼ˆä¸å«ç¨ï¼‰', 'å°è´¹', 'èˆå…¥', 'æ¡Œæ•°', 'é€€æ¬¾è®¢å•', 'è®¢å•æŠ˜æ‰£ç‡']
    data_df = df.iloc[header_row+1:].copy()
    
    # Handle case where there might be fewer columns than expected
    if data_df.shape[1] < len(columns):
        actual_columns = columns[:data_df.shape[1]]
        data_df.columns = actual_columns
    else:
        data_df.columns = columns + [f'col_{i}' for i in range(len(columns), data_df.shape[1])]
    
    # Clean and convert data
    data_df = data_df.dropna(subset=['æ—¶é—´'])
    data_df['è®¢å•ç¨å‰å®æ”¶é‡‘é¢_float'] = data_df['è®¢å•ç¨å‰å®æ”¶é‡‘é¢Totals'].apply(convert_currency_to_float)
    data_df['å°±é¤äººæ•°'] = pd.to_numeric(data_df['å°±é¤äººæ•°'], errors='coerce').fillna(0)
    data_df['åˆ†æ—¶æ®µ'] = data_df['æ—¶é—´'].apply(categorize_time_segment)
    
    # Process additional columns if available
    if 'æ¡Œæ•°' in data_df.columns:
        data_df['æ¡Œæ•°'] = pd.to_numeric(data_df['æ¡Œæ•°'], errors='coerce').fillna(0)
    else:
        data_df['æ¡Œæ•°'] = 1
    
    if 'è®¢å•æŠ˜æ‰£ç‡' in data_df.columns:
        data_df['è®¢å•æŠ˜æ‰£ç‡'] = pd.to_numeric(data_df['è®¢å•æŠ˜æ‰£ç‡'], errors='coerce').fillna(1.0)
    else:
        data_df['è®¢å•æŠ˜æ‰£ç‡'] = 1.0
    
    if 'é€€æ¬¾è®¢å•' in data_df.columns:
        data_df['æ˜¯å¦é€€æ¬¾'] = data_df['é€€æ¬¾è®¢å•'] == 'æ˜¯'
    else:
        data_df['æ˜¯å¦é€€æ¬¾'] = False
    
    if 'æŠ˜æ‰£é‡‘é¢ï¼ˆåˆè®¡ï¼‰' in data_df.columns:
        data_df['æŠ˜æ‰£é‡‘é¢_float'] = data_df['æŠ˜æ‰£é‡‘é¢ï¼ˆåˆè®¡ï¼‰'].apply(convert_currency_to_float).abs()  # Take absolute value
    else:
        data_df['æŠ˜æ‰£é‡‘é¢_float'] = 0.0
    
    # Parse date
    date_str = sheet_name.replace('-', '')
    
    # Group by time segment
    time_segments = []
    for segment in ["08:00-13:59", "14:00-16:59", "17:00-21:59", "22:00-(æ¬¡)07:59"]:
        segment_data = data_df[data_df['åˆ†æ—¶æ®µ'] == segment]
        
        if len(segment_data) > 0:
            # Filter out refund orders for this segment
            valid_segment_orders = segment_data[~segment_data['æ˜¯å¦é€€æ¬¾'] & (segment_data['æ¡Œæ•°'] > 0)]
            
            # Calculate metrics for this time segment
            segment_è¥ä¸šæ¡Œæ•° = valid_segment_orders['æ¡Œæ•°'].sum()
            qualified_segment_orders = valid_segment_orders[valid_segment_orders['è®¢å•æŠ˜æ‰£ç‡'] >= 0.7]
            segment_è¥ä¸šæ¡Œæ•°_è€ƒæ ¸ = (qualified_segment_orders['æ¡Œæ•°'] * qualified_segment_orders['è®¢å•æŠ˜æ‰£ç‡']).sum()
            segment_revenue = valid_segment_orders['è®¢å•ç¨å‰å®æ”¶é‡‘é¢_float'].sum()
            segment_customers = valid_segment_orders['å°±é¤äººæ•°'].sum()
            segment_discount = valid_segment_orders['æŠ˜æ‰£é‡‘é¢_float'].sum()
            
            segment_info = {
                'æ—¥æœŸ': date_str,
                'å›½å®¶': store_info['country'],
                'å¤§åŒºç»ç†': store_info['regional_manager'],
                'é—¨åº—åç§°': store_info['store_name'],
                'åˆ†æ—¶æ®µ': segment,
                'èŠ‚å‡æ—¥': store_info['holiday_type'],
                'æ‰€æœ‰é¤ä½æ•°': store_info['total_seats'],
                
                # Required columns for time segment extraction
                'è¥ä¸šæ¡Œæ•°(è€ƒæ ¸)': round(segment_è¥ä¸šæ¡Œæ•°_è€ƒæ ¸, 2),
                'ç¿»å°ç‡(è€ƒæ ¸)': round(segment_è¥ä¸šæ¡Œæ•°_è€ƒæ ¸ / max(1, store_info['total_seats']), 2),
                
                # Additional time segment metrics
                'è¥ä¸šæ¡Œæ•°': int(segment_è¥ä¸šæ¡Œæ•°),
                'å°±é¤äººæ•°': int(segment_customers),
                'è¥ä¸šé¢': round(segment_revenue, 2),
                'ç¿»å°ç‡': round(segment_è¥ä¸šæ¡Œæ•° / max(1, store_info['total_seats']), 2),
                'ä¼˜æƒ æ€»é‡‘é¢(ä¸å«ç¨)': round(segment_discount, 2),
            }
        else:
            # Create empty segment data
            segment_info = {
                'æ—¥æœŸ': date_str,
                'å›½å®¶': store_info['country'],
                'å¤§åŒºç»ç†': store_info['regional_manager'],
                'é—¨åº—åç§°': store_info['store_name'],
                'åˆ†æ—¶æ®µ': segment,
                'èŠ‚å‡æ—¥': store_info['holiday_type'],
                'æ‰€æœ‰é¤ä½æ•°': store_info['total_seats'],
                
                # Required columns for time segment extraction
                'è¥ä¸šæ¡Œæ•°(è€ƒæ ¸)': 0.0,
                'ç¿»å°ç‡(è€ƒæ ¸)': 0.0,
                
                # Additional time segment metrics  
                'è¥ä¸šæ¡Œæ•°': 0,
                'å°±é¤äººæ•°': 0,
                'è¥ä¸šé¢': 0.0,
                'ç¿»å°ç‡': 0.0,
                'ä¼˜æƒ æ€»é‡‘é¢(ä¸å«ç¨)': 0.0,
            }
        
        time_segments.append(segment_info)
    
    return time_segments

def create_haidilao_format_excel(daily_data_list, time_segment_data_list, output_file):
    """Create Excel file in Haidilao format with proper styling."""
    
    # Create output directory if it doesn't exist
    output_dir = os.path.dirname(output_file)
    if output_dir:
        os.makedirs(output_dir, exist_ok=True)
    
    # Create DataFrames first
    daily_df = pd.DataFrame(daily_data_list)
    time_df = pd.DataFrame(time_segment_data_list)
    
    # Write to Excel file using pandas for better compatibility
    with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
        daily_df.to_excel(writer, sheet_name='è¥ä¸šåŸºç¡€è¡¨', index=False)
        time_df.to_excel(writer, sheet_name='åˆ†æ—¶æ®µåŸºç¡€è¡¨', index=False)
    
    print(f"âœ… Converted Excel file saved: {output_file}")

def convert_other_source_to_haidilao(input_file, output_file, store_config=None, is_test=False):
    """Main conversion function."""
    
    # Default store configuration (you can customize this)
    default_store_info = {
        'country': 'åŠ æ‹¿å¤§',
        'regional_manager': 'è’‹å†°é‡',
        'store_name': 'åŠ æ‹¿å¤§å…­åº—',  # Default to recognized store
        'store_code': '119812',
        'opening_date': '2024-01-09',
        'holiday_type': 'èŠ‚å‡æ—¥',
        'total_seats': 56,
    }
    
    store_info = store_config if store_config else default_store_info
    
    print(f"ğŸ”„ Converting {input_file} to Haidilao format...")
    print(f"ğŸ“ Store: {store_info['store_name']} ({store_info['store_code']})")
    
    # Try to get actual store information from database
    db_store_info = get_store_info_from_database(store_info['store_name'], store_info['store_code'], is_test)
    if db_store_info:
        print(f"âœ… Found store in database with {db_store_info['total_seats']} seats")
        store_info = db_store_info
    else:
        print(f"âš ï¸  Using default configuration with {store_info['total_seats']} seats")
    
    # Read all sheets from the input file
    excel_file = pd.ExcelFile(input_file)
    sheet_names = [name for name in excel_file.sheet_names if name.startswith('2025-')]
    
    print(f"ğŸ“Š Found {len(sheet_names)} daily sheets to process")
    
    daily_data_list = []
    time_segment_data_list = []
    
    for sheet_name in sorted(sheet_names):
        print(f"  ğŸ“… Processing {sheet_name}...")
        df = pd.read_excel(input_file, sheet_name=sheet_name, header=None)
        
        # Process daily aggregation
        daily_data = process_daily_sheet(sheet_name, df, store_info)
        if daily_data:
            daily_data_list.append(daily_data)
        
        # Process time segment breakdown
        time_segments = process_time_segment_sheet(sheet_name, df, store_info)
        time_segment_data_list.extend(time_segments)
    
    print(f"ğŸ“‹ Generated {len(daily_data_list)} daily records")
    print(f"â° Generated {len(time_segment_data_list)} time segment records")
    
    # Create output Excel file
    create_haidilao_format_excel(daily_data_list, time_segment_data_list, output_file)
    
    return True

def main():
    parser = argparse.ArgumentParser(description='Convert other source Excel format to Haidilao format')
    parser.add_argument('input_file', help='Path to the other source Excel file')
    parser.add_argument('--output', '-o', help='Output file path', default='output/converted_haidilao_format.xlsx')
    parser.add_argument('--store-name', help='Store name to use in conversion', default='åŠ æ‹¿å¤§å…­åº—')
    parser.add_argument('--store-code', help='Store code to use in conversion', default='119812')
    parser.add_argument('--country', help='Country name', default='åŠ æ‹¿å¤§')
    parser.add_argument('--manager', help='Regional manager name', default='è’‹å†°é‡')
    parser.add_argument('--test', action='store_true', help='Use test database instead of production')
    
    args = parser.parse_args()
    
    # Validate input file
    if not Path(args.input_file).exists():
        print(f"âŒ Input file not found: {args.input_file}")
        sys.exit(1)
    
    # Create store configuration
    store_config = {
        'country': args.country,
        'regional_manager': args.manager,
        'store_name': args.store_name,
        'store_code': args.store_code,
        'opening_date': '2024-01-01',
        'holiday_type': 'èŠ‚å‡æ—¥',
        'total_seats': 60,
    }
    
    print("ğŸ² Haidilao Format Converter")
    print("=" * 50)
    
    # Perform conversion
    if convert_other_source_to_haidilao(args.input_file, args.output, store_config, args.test):
        print("\nğŸ‰ Conversion completed successfully!")
        print(f"ğŸ“„ Output file: {args.output}")
        print(f"ğŸ’¡ You can now use this file with: python3 scripts/extract-all.py {args.output}")
    else:
        print("\nâŒ Conversion failed!")
        sys.exit(1)

if __name__ == '__main__':
    main() 